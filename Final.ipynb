{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data structures\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#used for feature engineering(signal processing tools)\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch\n",
    "from siml.sk_utils import *\n",
    "from siml.signal_analysis_utils import *\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef,make_scorer\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectra(signals, *, m = 1000):\n",
    "    '''\n",
    "    computes the mean and percentiles by combining different phases belonging to th same signal\n",
    "    '''\n",
    "    means = []\n",
    "    percentiles = []\n",
    "    percentile_values = (100,99,95,0,1,5)\n",
    "    for raw_signal in tqdm(signals):\n",
    "        \n",
    "        #normalizing the signal values \n",
    "        signal = raw_signal.astype('float32').reshape(-1, m) / 128.0\n",
    "        \n",
    "        #mean of signal\n",
    "        mean = np.mean(signal,axis=1)\n",
    "        \n",
    "        #percentiles of signal\n",
    "        percentile = np.abs(np.percentile(signal,percentile_values,axis=1)-mean)\n",
    "        \n",
    "        #calaculating the baseline of percentiles\n",
    "        baseline = np.percentile(percentile,5.0)\n",
    "        \n",
    "        #subtracting the baseline\n",
    "        percentile = np.maximum(0.0,percentile-baseline)\n",
    "        \n",
    "        means.append(mean)\n",
    "        \n",
    "        percentiles.append(percentile.T)\n",
    "        \n",
    "    res = {}\n",
    "    res['mean'] = np.array(means)\n",
    "    res['percentile'] = np.array(percentiles)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/junkoda/handmade-features\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "def max_windowed(spec, *, width=150, stride=10):\n",
    "    \"\"\"\n",
    "    Smooth the spectrum with a tophat window function and find the\n",
    "    peak inteval that maximises the smoothed spectrum.\n",
    "    \n",
    "    Returns: d(dict)\n",
    "      d['w'] (array): smoothed max - mean spectrum\n",
    "      d['ibegin'] (array): the left edge index of the peak interval\n",
    "    \"\"\"\n",
    "    n = spec.shape[0]\n",
    "    length = spec.shape[1] # 800\n",
    "    nspec = spec.shape[2] # 6 spectra\n",
    "\n",
    "    n_triplet = n // 3\n",
    "\n",
    "    # Reorganize the max spectrum from 8712 data to 2904 triplets with 3 phases\n",
    "    max_spec3 = np.empty((n_triplet, length, 3))\n",
    "    for i_triplet in range(n_triplet):\n",
    "        max_spec3[i_triplet, :, 0] = spec[3*i_triplet, :, 0] # phase 0\n",
    "        max_spec3[i_triplet, :, 1] = spec[3*i_triplet + 1, :, 0] # phase 1\n",
    "        max_spec3[i_triplet, :, 2] = spec[3*i_triplet + 2, :, 0] # phase 2\n",
    "\n",
    "    x = tf.compat.v1.placeholder(tf.float32, [None, length, 3]) # input spectra before smoothing\n",
    "    # 800 -> 80: static convolaution\n",
    "    # convolution but not CNN, the kernel is static\n",
    "    # smoothing/convolution kernel\n",
    "    # tophat window function\n",
    "    # shape (3, 1) adds up 3 phases to one output\n",
    "    K = np.ones((width, 3, 1), dtype='float32') / width\n",
    "\n",
    "    W_conv1 = tf.constant(K)\n",
    "    h_conv1 = tf.nn.conv1d(x, W_conv1, stride=stride, padding='VALID')\n",
    "    \n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        w = sess.run(h_conv1, feed_dict={x:max_spec3})\n",
    "\n",
    "    imax = np.argmax(w[:, :, 0], axis=1) # index of maximum smoothed spectrum\n",
    "    \n",
    "    d = {}\n",
    "    d['w'] = w # smoothed max spectrum\n",
    "    d['ibegin'] = imax*stride\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectra_features(spectra,peaks):\n",
    "    '''\n",
    "    extracts the features from peaks found in percentiles and means\n",
    "    '''\n",
    "    \n",
    "    percentiles = spectra['percentile']\n",
    "    \n",
    "    n = percentiles.shape[0]\n",
    "    length = percentiles.shape[1]\n",
    "    nspec = percentiles.shape[2]\n",
    "    \n",
    "    n_signals = n//3\n",
    "    \n",
    "    phase_percentiles = np.empty((n_signals,length,nspec,3))\n",
    "    \n",
    "    #creating an array which combines all 3 phases\n",
    "    for i_signal in range(n_signals):\n",
    "        phase_percentiles[i_signal, :, :, 0] = percentiles[3*i_signal, :, :] # phase 0\n",
    "        phase_percentiles[i_signal, :, :, 1] = percentiles[3*i_signal + 1, :, :] # phase 1\n",
    "        phase_percentiles[i_signal, :, :, 2] = percentiles[3*i_signal + 2, :, :] # phase 2\n",
    "    \n",
    "    \n",
    "    width = 150\n",
    "    \n",
    "    n_perc_features = 3\n",
    "    \n",
    "    #array to store final features\n",
    "    spectra_features = np.empty((n_signals,n_perc_features*nspec*3 + 3))\n",
    "    \n",
    "    #array to store percentile features\n",
    "    perc_phase_features = np.empty((n_signals,n_perc_features,nspec,3))\n",
    "    \n",
    "    \n",
    "    for i_signal in range(n_signals):\n",
    "        \n",
    "        #max of the total percentile features\n",
    "        perc_phase_features[i_signal,0,:,:] = np.max(phase_percentiles[i_signal,:,:,:],axis = 0)\n",
    "        \n",
    "        peak_start = peaks['ibegin'][i_signal]\n",
    "        peak_end = peak_start +width\n",
    "        peak_mid = peak_start+width//2\n",
    "        \n",
    "        #mean of the percentle features in peak interval\n",
    "        perc_phase_features[i_signal,1,:,:] = np.mean(phase_percentiles[i_signal,peak_start:peak_end,:,:],axis = 0)\n",
    "        \n",
    "        #max of the percentle features in peak interval\n",
    "        perc_phase_features[i_signal,2,:,:] = np.max(phase_percentiles[i_signal,peak_start:peak_end,:,:],axis = 0)\n",
    "        \n",
    "        #storing the mean value at the mid index of peak interval of each phase\n",
    "        spectra_features[i_signal,0] = spectra['mean'][3*i_signal,peak_mid]\n",
    "        spectra_features[i_signal,1] = spectra['mean'][3*i_signal+1,peak_mid]\n",
    "        spectra_features[i_signal,2] = spectra['mean'][3*i_signal+2,peak_mid]\n",
    "     \n",
    "    #storing all the features\n",
    "    shape = perc_phase_features.shape\n",
    "    spectra_features[:,3:] = perc_phase_features.reshape(shape[0], shape[1]*shape[2]*shape[3])\n",
    "    \n",
    "    return spectra_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fourier_features(signal,N=800000,T=1/50):\n",
    "    '''\n",
    "    converts a signal from time spectrum to frequency spectrum\n",
    "    and returns only the features required as mentioned above\n",
    "    '''\n",
    "    fourier_values = fft(signal)\n",
    "    fourier_values_filtered = 2.0/N * np.abs(fourier_values[0:N//2])\n",
    "    return fourier_values_filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features_fourier(features,mph,no_features=8):\n",
    "    '''\n",
    "    returns fourier transformed features by extracting peaks and \n",
    "    considering only required number of peaks.\n",
    "    mph-detect peaks that are greater than minimum peak height\n",
    "    '''\n",
    "    indices_peaks = detect_peaks(features,mph = mph)\n",
    "    #print(indices_peaks)\n",
    "    values = features[indices_peaks]\n",
    "    if len(values)< no_features:\n",
    "        return np.append(values , [0]*(no_features-len(values)))\n",
    "    else:\n",
    "        return values[:no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_psd_features(signal,fs=50):\n",
    "    '''\n",
    "    returns the features from a time spectrum signal(similiar to fft \n",
    "    but also considers power spectral density)\n",
    "    '''\n",
    "    f_values, psd_values = welch(signal, fs=50)\n",
    "    return psd_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stat_features(signal_features):\n",
    "    '''\n",
    "    used to extract statistical features from power spectral density\n",
    "    '''\n",
    "    percentiles = (5,25,50,75)\n",
    "    #array to store\n",
    "    filtered_features = np.zeros(8)\n",
    "    #mean\n",
    "    filtered_features[0] = np.mean(signal_features,axis=0)\n",
    "    #standard deviation\n",
    "    filtered_features[1] = np.std(signal_features,axis=0)\n",
    "    #maximum\n",
    "    filtered_features[2] = np.max(signal_features,axis=0)\n",
    "    #minimum\n",
    "    filtered_features[3] = np.min(signal_features,axis=0)\n",
    "    #mean\n",
    "    filtered_features[4] = np.mean(signal_features,axis=0)\n",
    "    #percentiles\n",
    "    filtered_features[4:] = np.percentile(signal_features,percentiles,axis=0).T\n",
    "    \n",
    "    return filtered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    '''\n",
    "    returns the prediction for raw input\n",
    "    '''\n",
    "\n",
    "    spectra = compute_spectra(X)\n",
    "\n",
    "    peaks = max_windowed(spectra['percentile'])\n",
    "\n",
    "    spectra_features = compute_spectra_features(spectra, peaks)\n",
    "\n",
    "    signal_features = []\n",
    "    for i in tqdm(range(0,len(X),3)):\n",
    "\n",
    "        std = 0\n",
    "        maxs = 0\n",
    "        bw_low = 0\n",
    "\n",
    "        #arrays to store features\n",
    "        fourier_features = np.empty((3,8))\n",
    "        psd_features = np.empty((3,129))\n",
    "        features = []\n",
    "\n",
    "        for j in range(3):\n",
    "\n",
    "            signal = raw_signal_data[i+j]\n",
    "            #standard deviation\n",
    "            std += signal.std()\n",
    "            #max of signal\n",
    "            maxs += signal.max()\n",
    "            #lower bandwidth\n",
    "            bw_low += signal.mean()-signal.std()\n",
    "\n",
    "            #minimum peak height which can be used to filter fourier features\n",
    "            mph = signal.min() + (signal.max() - np.abs(signal.min()))/10\n",
    "\n",
    "            #fourier features\n",
    "            fourier_features_ = extract_fourier_features(signal)\n",
    "\n",
    "            fourier_features[j,:] = filter_features_fourier(fourier_features_,mph)\n",
    "\n",
    "            #power spectral density features\n",
    "            psd_features[j,:] = extract_psd_features(signal)\n",
    "\n",
    "        #calculating the average of above features\n",
    "\n",
    "        features.append(std/3)\n",
    "\n",
    "        features.append(maxs/3)\n",
    "\n",
    "        features.append(bw_low/3)\n",
    "\n",
    "        features.extend(np.mean(fourier_features,axis=0))\n",
    "\n",
    "        features.extend(extract_stat_features(np.mean(psd_features,axis=0)))\n",
    "\n",
    "\n",
    "        signal_features.append(features)\n",
    "\n",
    "    total_features = np.concatenate((spectra_features,signal_features),axis=1)\n",
    "\n",
    "    #loading the saved models\n",
    "    models = []\n",
    "    for i in range(20):\n",
    "        filename = 'finalmodels/model'+str(i)+'.sav'\n",
    "        model = pickle.load(open(filename,'rb'))\n",
    "        models.append(model)\n",
    "\n",
    "    #prediction   \n",
    "    y_test_probas = np.empty((total_features.shape[0], 20))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        y_test_probas[:, i] = model.predict_proba(total_features)[:, 1]\n",
    "\n",
    "    #taking mean of all the predicted \n",
    "    y_test_proba = np.mean(y_test_probas, axis=1)\n",
    "\n",
    "    # Converting to 0 1 with a threshold 0.25, then replicating 3 copies for 3 phases\n",
    "    y_pred = np.repeat(y_test_proba > 0.25, 3)\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X,Y):\n",
    "    '''\n",
    "    returns the matthews correlation score for raw input\n",
    "    '''\n",
    "\n",
    "    spectra = compute_spectra(X)\n",
    "\n",
    "    peaks = max_windowed(spectra['percentile'])\n",
    "\n",
    "    spectra_features = compute_spectra_features(spectra, peaks)\n",
    "\n",
    "    signal_features = []\n",
    "    for i in tqdm(range(0,len(X),3)):\n",
    "\n",
    "        std = 0\n",
    "        maxs = 0\n",
    "        bw_low = 0\n",
    "\n",
    "        #arrays to store features\n",
    "        fourier_features = np.empty((3,8))\n",
    "        psd_features = np.empty((3,129))\n",
    "        features = []\n",
    "\n",
    "        for j in range(3):\n",
    "\n",
    "            signal = raw_signal_data[i+j]\n",
    "            #standard deviation\n",
    "            std += signal.std()\n",
    "            #max of signal\n",
    "            maxs += signal.max()\n",
    "            #lower bandwidth\n",
    "            bw_low += signal.mean()-signal.std()\n",
    "\n",
    "            #minimum peak height which can be used to filter fourier features\n",
    "            mph = signal.min() + (signal.max() - np.abs(signal.min()))/10\n",
    "\n",
    "            #fourier features\n",
    "            fourier_features_ = extract_fourier_features(signal)\n",
    "\n",
    "            fourier_features[j,:] = filter_features_fourier(fourier_features_,mph)\n",
    "\n",
    "            #power spectral density features\n",
    "            psd_features[j,:] = extract_psd_features(signal)\n",
    "\n",
    "        #calculating the average of above features\n",
    "\n",
    "        features.append(std/3)\n",
    "\n",
    "        features.append(maxs/3)\n",
    "\n",
    "        features.append(bw_low/3)\n",
    "\n",
    "        features.extend(np.mean(fourier_features,axis=0))\n",
    "\n",
    "        features.extend(extract_stat_features(np.mean(psd_features,axis=0)))\n",
    "\n",
    "\n",
    "        signal_features.append(features)\n",
    "\n",
    "    total_features = np.concatenate((spectra_features,signal_features),axis=1)\n",
    "\n",
    "    #loading the saved models\n",
    "    models = []\n",
    "    for i in range(20):\n",
    "        filename = 'finalmodels/model'+str(i)+'.sav'\n",
    "        model = pickle.load(open(filename,'rb'))\n",
    "        models.append(model)\n",
    "\n",
    "    #prediction   \n",
    "    y_test_probas = np.empty((total_features.shape[0], 20))\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        y_test_probas[:, i] = model.predict_proba(total_features)[:, 1]\n",
    "\n",
    "    #taking mean of all the predicted \n",
    "    y_test_proba = np.mean(y_test_probas, axis=1)\n",
    "\n",
    "    # Converting to 0 1 with a threshold 0.25, then replicating 3 copies for 3 phases\n",
    "    y_pred = np.repeat(y_test_proba > 0.25, 3)\n",
    "\n",
    "    return matthews_corrcoef(y_pred,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
