{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf0ZbFVt4PtQ"
   },
   "source": [
    "<p style=\"font-size:36px;text-align:center\"> <b>VSB Power Line Fault Detection</b> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIQmkqR54Pti"
   },
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Lk7hzwDz4Ptj",
    "outputId": "3c50cb46-3598-4d79-f3ce-44d690ddd2d4"
   },
   "outputs": [],
   "source": [
    "#data structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import matthews_corrcoef,make_scorer\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the spectra features\n",
    "train_spectra_features = np.load('trainfeatures/train_spectra_features.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the signal\n",
    "train_sig_features = np.load('trainfeatures/train_signal_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the train labels\n",
    "train_labels = np.load('traindata/train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating the train features\n",
    "X_train_features = np.concatenate((train_spectra_features,train_sig_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2904, 76)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "for alpha = 1\n",
      "0 0.307 0.144\n",
      "1 0.274 0.290\n",
      "2 0.287 0.280\n",
      "3 0.265 0.280\n",
      "4 0.304 0.211\n",
      "CV scores 0.241 ± 0.056\n",
      "\n",
      "for alpha = 10\n",
      "0 0.562 0.428\n",
      "1 0.540 0.526\n",
      "2 0.492 0.451\n",
      "3 0.543 0.482\n",
      "4 0.534 0.421\n",
      "CV scores 0.462 ± 0.039\n",
      "\n",
      "for alpha = 100\n",
      "0 0.728 0.540\n",
      "1 0.685 0.604\n",
      "2 0.650 0.632\n",
      "3 0.685 0.666\n",
      "4 0.671 0.581\n",
      "CV scores 0.605 ± 0.043\n",
      "\n",
      "for alpha = 1000\n",
      "0 0.750 0.610\n",
      "1 0.725 0.666\n",
      "2 0.715 0.686\n",
      "3 0.732 0.680\n",
      "4 0.731 0.645\n",
      "CV scores 0.658 ± 0.028\n",
      "\n",
      "for alpha = 10000\n",
      "0 0.777 0.645\n",
      "1 0.752 0.708\n",
      "2 0.732 0.706\n",
      "3 0.746 0.688\n",
      "4 0.756 0.659\n",
      "CV scores 0.681 ± 0.025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and CV data\n",
    "n_splits = 5\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(X_train_features, train_labels))\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "\n",
    "alphas = [10**i for i in range(0,5)]\n",
    "cv_mccs = []\n",
    "for alpha in alphas:\n",
    "    print('for alpha = {}'.format(alpha))\n",
    "    for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "\n",
    "        #train and cv split\n",
    "        X_train = X_train_features[idx_train, :]\n",
    "        y_train = train_labels[idx_train]\n",
    "\n",
    "        X_cv = X_train_features[idx_cv, :]\n",
    "        y_cv = train_labels[idx_cv]\n",
    "\n",
    "        #initalizing and fitting the model\n",
    "        model =LogisticRegression(C=alpha,max_iter=4000)\n",
    "        model.fit(X_train, y_train.astype(float))\n",
    "\n",
    "        #prediction\n",
    "        y_predict_train = model.predict(X_train)\n",
    "        y_predict_cv = model.predict(X_cv)\n",
    "\n",
    "        #calculating mcc metric\n",
    "        score_train = matthews_corrcoef(y_train, y_predict_train)\n",
    "        score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "\n",
    "        #storing the models\n",
    "        models.append(model)\n",
    "        scores[i] = score_cv\n",
    "\n",
    "        #printing the train and cross validation mcc score\n",
    "        print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "    #average of all the scores\n",
    "    print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))\n",
    "    cv_mccs.append(np.mean(scores))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = alphas[np.argmax(cv_mccs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "0 0.758 0.624\n",
      "1 0.765 0.666\n",
      "2 0.740 0.719\n",
      "3 0.744 0.660\n",
      "4 0.727 0.673\n",
      "CV scores 0.668 ± 0.031\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(X_train_features, train_labels))\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "\n",
    "for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "\n",
    "    #train and cv split\n",
    "    X_train = X_train_features[idx_train, :]\n",
    "    y_train = train_labels[idx_train]\n",
    "\n",
    "    X_cv = X_train_features[idx_cv, :]\n",
    "    y_cv = train_labels[idx_cv]\n",
    "\n",
    "    #initalizing and fitting the model\n",
    "    model =LogisticRegression(C=best_alpha,max_iter=4000)\n",
    "    model.fit(X_train, y_train.astype(float))\n",
    "\n",
    "    #prediction\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict_cv = model.predict(X_cv)\n",
    "\n",
    "    #calculating mcc metric\n",
    "    score_train = matthews_corrcoef(y_train, y_predict_train)\n",
    "    score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "\n",
    "    #storing the models\n",
    "    models.append(model)\n",
    "    scores[i] = score_cv\n",
    "\n",
    "    #printing the train and cross validation mcc score\n",
    "    print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "#average of all the scores\n",
    "print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a scorer of mcc to use for randomsearchcv\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_score=False,\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': range(1, 16, 2),\n",
       "                                        'max_features': range(50, 70, 5),\n",
       "                                        'n_estimators': range(10, 500, 20)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False,\n",
       "                   scoring=make_scorer(matthews_corrcoef), verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using random search cv for finding best hyperparameters\n",
    "dt_cfl = RandomForestClassifier()\n",
    "params={'n_estimators' : range(10,500,20),'max_depth': range(1,16,2),'max_features':range(50,70,5)}\n",
    "\n",
    "rand_cv = RandomizedSearchCV(dt_cfl,param_distributions=params,verbose=0,n_jobs=-1,scoring=mcc_scorer)\n",
    "rand_cv.fit(X_train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=7, max_features=65,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=270,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "0 0.938 0.720\n",
      "1 0.958 0.739\n",
      "2 0.950 0.706\n",
      "3 0.969 0.680\n",
      "4 0.938 0.659\n",
      "CV scores 0.701 ± 0.028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and CV data\n",
    "n_splits = 5\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(X_train_features, train_labels))\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "    \n",
    "    #train and cv split\n",
    "    X_train = X_train_features[idx_train, :]\n",
    "    y_train = train_labels[idx_train]\n",
    "\n",
    "    X_cv = X_train_features[idx_cv, :]\n",
    "    y_cv = train_labels[idx_cv]\n",
    "    \n",
    "    #initalizing and fitting the model\n",
    "    model =RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=7, max_features=65,\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=270,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "    model.fit(X_train, y_train.astype(float))\n",
    "\n",
    "    #prediction\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict_cv = model.predict(X_cv)\n",
    "    \n",
    "    #calculating mcc metric\n",
    "    score_train = matthews_corrcoef(y_train, y_predict_train)\n",
    "    score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "    \n",
    "    #storing the models\n",
    "    models.append(model)\n",
    "    scores[i] = score_cv\n",
    "    \n",
    "    #printing the train and cross validation mcc score\n",
    "    print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "#average of all the scores\n",
    "print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=None, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, sile...\n",
       "                                            subsample_freq=0),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'lambda_l1': [0, 0.3, 1, 1.5],\n",
       "                                        'lambda_l2': [0, 0.3, 1],\n",
       "                                        'min_data_in_leaf': [30, 50, 100, 300,\n",
       "                                                             400],\n",
       "                                        'n_estimators': [100, 500, 1000, 1500],\n",
       "                                        'n_jobs': [-1], 'num_leaves': [31, 127],\n",
       "                                        'reg_alpha': [0.1, 0.5]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    " 'num_leaves': [31, 127],\n",
    " 'reg_alpha': [0.1, 0.5],\n",
    " 'min_data_in_leaf': [30, 50, 100, 300, 400],\n",
    " 'lambda_l1': [0, 0.3,1, 1.5],\n",
    " 'lambda_l2': [0,0.3, 1],\n",
    " 'n_estimators': [100,500,1000,1500],\n",
    " 'n_jobs':[-1]\n",
    " }\n",
    "lb = LGBMClassifier()\n",
    "lb_model = RandomizedSearchCV(lb, params, cv = 3,verbose=1,n_jobs=-1)\n",
    "lb_model.fit(X_train_features, train_labels,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', lambda_l1=0.3, lambda_l2=0.3,\n",
       "               learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0.0,\n",
       "               n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.1, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "0 1.000 0.795\n",
      "1 1.000 0.691\n",
      "2 1.000 0.623\n",
      "3 1.000 0.664\n",
      "4 1.000 0.795\n",
      "CV scores 0.714 ± 0.070\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and CV data\n",
    "n_splits = 5\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(X_train_features, train_labels))\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "    \n",
    "    #train and cv split\n",
    "    X_train = X_train_features[idx_train, :]\n",
    "    y_train = train_labels[idx_train]\n",
    "\n",
    "    X_cv = X_train_features[idx_cv, :]\n",
    "    y_cv = train_labels[idx_cv]\n",
    "    \n",
    "    #initalizing and fitting the model\n",
    "    learning_rate = 0.006\n",
    "    model = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "               importance_type='split', lambda_l1=0.3, lambda_l2=0.3,\n",
    "               learning_rate=0.006, max_depth=-1, min_child_samples=20,\n",
    "               min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0.0,\n",
    "               n_estimators=1000, n_jobs=-1, num_leaves=31, objective=None,\n",
    "               random_state=None, reg_alpha=0.1, reg_lambda=0.0, silent=True,\n",
    "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "    model.fit(X_train, y_train.astype(float))\n",
    "\n",
    "    #prediction\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict_cv = model.predict(X_cv)\n",
    "    \n",
    "    #calculating mcc metric\n",
    "    score_train = matthews_corrcoef(y_train, y_predict_train)\n",
    "    score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "    \n",
    "    #storing the models\n",
    "    models.append(model)\n",
    "    scores[i] = score_cv\n",
    "    \n",
    "    #printing the train and cross validation mcc score\n",
    "    print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "#average of all the scores\n",
    "print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=<catboost.core.CatBoostClassifier object at 0x7f2e605b5d30>,\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'depth': [5, 6, 7, 8, 9],\n",
       "                                        'iterations': [100, 200, 300, 400],\n",
       "                                        'l2_leaf_reg': [2, 4, 6, 8],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.005,\n",
       "                                                          0.01, 0.1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'depth': [5,6,7,8,9],\n",
    " 'learning_rate' : [0.0001, 0.001,0.005, 0.01, 0.1],\n",
    " 'l2_leaf_reg': [2,4,6,8],\n",
    " 'iterations': [100,200,300,400]}\n",
    "cb = CatBoostClassifier()\n",
    "cb_model = RandomizedSearchCV(cb, params,verbose=1,cv=3,n_jobs=-1)\n",
    "cb_model.fit(X_train_features, train_labels.astype(float),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f2e62ce7c18>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 9, 'iterations': 400, 'l2_leaf_reg': 4, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "0 0.829 0.787\n",
      "1 0.607 0.632\n",
      "2 0.820 0.769\n",
      "3 0.712 0.739\n",
      "4 0.926 0.695\n",
      "CV scores 0.724 ± 0.056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and CV data\n",
    "n_splits = 5\n",
    "splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True).split(X_train_features, train_labels))\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "    \n",
    "    #train and cv split\n",
    "    X_train = X_train_features[idx_train, :]\n",
    "    y_train = train_labels[idx_train]\n",
    "\n",
    "    X_cv = X_train_features[idx_cv, :]\n",
    "    y_cv = train_labels[idx_cv]\n",
    "    \n",
    "    #initalizing and fitting the model\n",
    "    learning_rate = 0.006\n",
    "    model = CatBoostClassifier(learning_rate=0.01,depth=9,l2_leaf_reg=4, od_type='IncToDec',\n",
    "                            loss_function='Logloss', use_best_model=True, eval_metric='MCC')\n",
    "    model.fit(X_train, y_train.astype(float), eval_set=(X_cv, y_cv.astype(float)),silent=True)\n",
    "\n",
    "    #prediction\n",
    "    y_predict_train = model.predict(X_train)\n",
    "    y_predict_cv = model.predict(X_cv)\n",
    "    \n",
    "    #calculating mcc metric\n",
    "    score_train = matthews_corrcoef(y_train, y_predict_train)\n",
    "    score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "    \n",
    "    #storing the models\n",
    "    models.append(model)\n",
    "    scores[i] = score_cv\n",
    "    \n",
    "    #printing the train and cross validation mcc score\n",
    "    print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "#average of all the scores    \n",
    "print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "catboostclassifier got the best mcc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "'''\n",
    "for i,model in enumerate(models):\n",
    "    filename = 'model'+str(i)+'.sav'\n",
    "    pickle.dump(model,open(filename,'wb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the catboost model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spectra_features = np.load('testfeatures/test_spectra_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_spectra_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_signal_features = np.load('testfeatures/test_signal_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_signal_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.concatenate((test_spectra_features,test_signal_features),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6779, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive fraction 828/20337 = 0.041\n"
     ]
    }
   ],
   "source": [
    "y_test_probas = np.empty((test_features.shape[0], n_splits))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    y_test_probas[:, i] = model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "#taking mean of all the predicted \n",
    "y_test_proba = np.mean(y_test_probas, axis=1)\n",
    "\n",
    "# Converting to 0 1 with a threshold 0.25, then replicating 3 copies for 3 phases\n",
    "y_submit = np.repeat(y_test_proba > 0.25, 3)\n",
    "\n",
    "print('Positive fraction %d/%d = %.3f' % (\n",
    "    np.sum(y_submit), len(y_submit), np.sum(y_submit)/len(y_submit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe and converting it into csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "uM6gFAnJ90eE"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1xtry9Ay-JAi"
   },
   "outputs": [],
   "source": [
    "signal_id = list(range(len(y_submit)))\n",
    "signal_id = [i+8712 for i in signal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cgwSQQS--deS"
   },
   "outputs": [],
   "source": [
    "results_df['signal_id'] = signal_id\n",
    "results_df['target'] = y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6n8EqfT2-wMJ",
    "outputId": "ec9eb67f-a474-46df-9bfe-f3873f8dd219"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20332</th>\n",
       "      <td>29044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20333</th>\n",
       "      <td>29045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20334</th>\n",
       "      <td>29046</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>29047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>29048</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       signal_id  target\n",
       "0           8712   False\n",
       "1           8713   False\n",
       "2           8714   False\n",
       "3           8715   False\n",
       "4           8716   False\n",
       "...          ...     ...\n",
       "20332      29044   False\n",
       "20333      29045   False\n",
       "20334      29046   False\n",
       "20335      29047   False\n",
       "20336      29048   False\n",
       "\n",
       "[20337 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uFtw5Q9U9x-W"
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('submission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the above results(mcc score of 62) to increase the data points\n",
    "knowledge_data = pd.read_csv('submission1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2904, 76) (2904,)\n",
      "(6779, 76) (6779,)\n"
     ]
    }
   ],
   "source": [
    "len_train=len(X_train_features)\n",
    "\n",
    "y_list=knowledge_data['target'].values\n",
    "y_test=[]\n",
    "for j in range(0,len(y_list),3):\n",
    "    y_test.append(y_list[j])\n",
    "y_test=np.asarray(y_test)\n",
    "del knowledge_data\n",
    "\n",
    "print(X_train_features.shape,train_labels.shape)\n",
    "print(test_features.shape,y_test.shape)\n",
    "\n",
    "X = np.concatenate([X_train_features,test_features])\n",
    "Y = np.concatenate([train_labels,y_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "MCC training & cv\n",
      "CV scores 0.880 ± 0.018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# split into train and CV data\n",
    "n_splits = 5\n",
    "\n",
    "models = []\n",
    "scores = np.zeros(n_splits)\n",
    "\n",
    "print('Training...')\n",
    "print('MCC training & cv') # MCC = Matthews Correlation Coefficient\n",
    "\n",
    "\n",
    "seeds=[0,42,1204,2019]\n",
    "for seed in seeds:\n",
    "    splits = list(StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed).split(X, Y))\n",
    "\n",
    "    for i, (idx_train, idx_cv) in enumerate(splits):\n",
    "        X_train = X[idx_train, :]\n",
    "        y_train = Y[idx_train]\n",
    "\n",
    "        X_cv = X[idx_cv, :]\n",
    "        y_cv = Y[idx_cv]\n",
    "\n",
    "        # Learning rate is important; large values overfit the data\n",
    "        learning_rate = 0.006\n",
    "        model = CatBoostClassifier(learning_rate=learning_rate, od_type='IncToDec',\n",
    "                                loss_function='Logloss', use_best_model=True, eval_metric='MCC')\n",
    "\n",
    "        model.fit(X_train, y_train.astype(float), silent=True,\n",
    "                  eval_set=(X_cv, y_cv.astype(float)))\n",
    "\n",
    "        y_predict_train = model.predict(X_train)\n",
    "        y_predict_cv = model.predict(X_cv)\n",
    "\n",
    "    #     score_train = sklearn.metrics.matthews_corrcoef(y_train, y_predict_train)\n",
    "        score_cv = matthews_corrcoef(y_cv, y_predict_cv)\n",
    "\n",
    "        models.append(model)\n",
    "        scores[i] = score_cv\n",
    "    \n",
    "#     print('%d %.3f %.3f' % (i, score_train, score_cv))\n",
    "\n",
    "print('CV scores %.3f ± %.3f' % (np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive fraction 894/20337 = 0.044\n"
     ]
    }
   ],
   "source": [
    "y_test_probas = np.empty((test_features.shape[0], n_splits*len(seeds)))\n",
    "\n",
    "# assert(len(models) == n_splits)\n",
    "for i, model in enumerate(models):\n",
    "    y_test_probas[:, i] = model.predict_proba(test_features)[:, 1]\n",
    "\n",
    "y_test_proba = np.mean(y_test_probas, axis=1)\n",
    "\n",
    "# Convert to 0 1 with a threshold 0.25, then replicate 3 copies for 3 phases\n",
    "y_submit = np.repeat(y_test_proba > 0.30, 3)\n",
    "\n",
    "print('Positive fraction %d/%d = %.3f' % (\n",
    "    np.sum(y_submit), len(y_submit), np.sum(y_submit)/len(y_submit)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "uM6gFAnJ90eE"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1xtry9Ay-JAi"
   },
   "outputs": [],
   "source": [
    "signal_id = list(range(len(y_submit)))\n",
    "signal_id = [i+8712 for i in signal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cgwSQQS--deS"
   },
   "outputs": [],
   "source": [
    "results_df['signal_id'] = signal_id\n",
    "results_df['target'] = y_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6n8EqfT2-wMJ",
    "outputId": "ec9eb67f-a474-46df-9bfe-f3873f8dd219"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8712</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8714</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8715</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8716</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20332</th>\n",
       "      <td>29044</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20333</th>\n",
       "      <td>29045</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20334</th>\n",
       "      <td>29046</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>29047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20336</th>\n",
       "      <td>29048</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20337 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       signal_id  target\n",
       "0           8712   False\n",
       "1           8713   False\n",
       "2           8714   False\n",
       "3           8715   False\n",
       "4           8716   False\n",
       "...          ...     ...\n",
       "20332      29044   False\n",
       "20333      29045   False\n",
       "20334      29046   False\n",
       "20335      29047   False\n",
       "20336      29048   False\n",
       "\n",
       "[20337 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uFtw5Q9U9x-W"
   },
   "outputs": [],
   "source": [
    "results_df.to_csv('submission2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
